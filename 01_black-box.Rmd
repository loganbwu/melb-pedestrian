---
title: "Black Box Methods"
author: "Logan Wu"
date: "1/8/2019"
output: rmarkdown::github_document
always_allow_html: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo=T, cache=F)
library(data.table)
library(sf)
library(leaflet)
library(spdep)     # easily create weight matrices
library(starma)
library(forecast)
library(ggcorrplot)
library(tidyverse)
library(xts)
library(plotly)
library(xtable)
library(knitr)
library(ranger)
```

## Load data

```{r}
# read in a manageable portion of the dataset for now
raw.ts <- fread("data/Pedestrian_volume__updated_monthly_.csv", nrows=50000)
raw.ts[,Date_Time := as.POSIXct(Date_Time, format="%m/%d/%Y %I:%M:%S %p")]
```

## Process data

Feature vector includes:

- n hours of lags
- Time of day
- Day of week
- Sensor name or ID

Could include:

- Month of year, and year (or some other trend term)
- Public holiday

```{r}
nlag = 3

locs = make.names(unique(raw.ts$Sensor_Name))
data.ts = raw.ts %>%
  dplyr::select(Date_Time, Sensor_Name, Hourly_Counts) %>%
  spread(key=Sensor_Name, value=Hourly_Counts) %>%
  as.xts(frequency=168) %>%
  as.zoo %>%
  na.contiguous %>%# analysis does not include missing data
  as.data.frame %>%
  mutate(time=as.POSIXct(rownames(.)),
         day=factor(weekdays(time)),
         hour=hour(time))
old.names = names(data.ts)
names(data.ts) = make.names(old.names)
new.names = names(data.ts)

lags = list()
lags_ix = c(1:nlag, 24, 168)
for (i in seq_along(lags_ix)) {
  lags[[i]] = data.ts %>%
    dplyr::select(-time, -day, -hour) %>%
    mutate_all(function (x) lead(x, lags_ix[i])) %>%
    rename_all(function(x) paste0(x,".lag", lags_ix[i]))
}
lags = do.call(cbind, lags)

# append the lags onto each current measurement
X = list()
for (j in seq_along(locs)) {
  X[[j]] = cbind(Hourly_Counts=data.ts[,locs[j]], 
                 day=data.ts$day, 
                 hour=data.ts$hour, 
                 time=data.ts$time,
                 location=locs[j],
                 lags)
}
X = do.call(rbind, X) %>%
  drop_na() %>%
  arrange(time)
names(X) = make.names(names(X))
X %>% head %>% kable
```

## Check collinearity/VIFs

Just compare each series with others, not between lags of a single series.

```{r}
library(usdm)
df = X %>% dplyr::select(ends_with(".lag1"))
v = vif(df) %>%
  mutate(Variables=str_remove(Variables, "\\.lag1")) %>%
  mutate(Variables=mapvalues(Variables, from=new.names, to=old.names))
ggplot(v %>% filter(Variables %in% v$Variables[1:10]), aes(x=Variables, y=VIF, fill=VIF)) +
  ylab("Variance Inflation Factor") +
  geom_col() + coord_flip() +
  theme_minimal() +
  scale_fill_gradient(low="#553333", high="#CC3333") +
  geom_text(aes(label=Variables), hjust="right", vjust="center", color="white", nudge_y=-0.01) +
  theme(axis.title.y=element_blank(),
        axis.text.y=element_blank(),
        axis.ticks.y=element_blank(),
        panel.grid.major = element_blank(),
        panel.grid.minor = element_blank()) +
  guides(fill=F) +
  scale_y_log10(breaks=c(1,2,4,6,8,10,20,40,60,100)) +
  ggsave(file="vif.pdf", width=4, height=2)
```


## Test RF on train/test split

```{r}
frac = 0.8
X.train = head(X, round(nrow(X)*frac))
X.test = tail(X, round(nrow(X)*(1-frac)))
y.test = X.test %>% pull(Hourly_Counts)
```

Exclude the time and weekday from the model. Purely regressed on lags from the past three hours.

```{r}
rf <- ranger(Hourly_Counts ~ . -hour -day -time, num.trees=100, data=X.train)
```
```{r}
pred <- predict(rf, X.test)
X.test$pred = pred$predictions
ggplot(X.test, aes(x=Hourly_Counts, y=pred)) +
  geom_point(alpha=0.25)
cat("RMSE", sqrt(mean((X.test$Hourly_Counts-X.test$pred)^2)), "\n")
cat("MAE", mean(abs(X.test$Hourly_Counts-X.test$pred)))

plt.df.train = X.train %>%
  dplyr::select(time, location, train=Hourly_Counts) %>%
  gather(key="key", value="value", -time, -location)
plt.df.test = X.test %>%
  dplyr::select(time, location, obs=Hourly_Counts, fcst=pred) %>%
  gather(key="key", value="value", -time, -location)
plt.df = rbind(plt.df.train, plt.df.test)

ggplot(plt.df %>% filter(location %in% levels(plt.df$location)[1:6]),
       aes(x=time, y=value, color=key)) +
  geom_line(alpha=0.5) +
  facet_wrap(~location, ncol=1) +
  ylim(0, NA)
```

Introduce time and weekday. Would expect it to improve.

```{r}
rf2 <- ranger(Hourly_Counts ~ . -time, num.trees=100, data=X.train)
```
```{r}
pred2 <- predict(rf2, X.test)
X.test$pred2 = pred2$predictions
ggplot(X.test, aes(x=Hourly_Counts, y=pred2)) +
  geom_point(alpha=0.25)
cat("RMSE", sqrt(mean((X.test$Hourly_Counts-X.test$pred2)^2)), "\n")
cat("MAE", mean(abs(X.test$Hourly_Counts-X.test$pred2)))

plt.df.train = X.train %>%
  dplyr::select(time, location, train=Hourly_Counts) %>%
  gather(key="key", value="value", -time, -location)
plt.df.test = X.test %>%
  dplyr::select(time, location, obs=Hourly_Counts, fcst=pred2) %>%
  gather(key="key", value="value", -time, -location)
plt.df = rbind(plt.df.train, plt.df.test)

ggplot(plt.df %>% filter(location %in% levels(plt.df$location)[1:6]),
       aes(x=time, y=value, color=key)) +
  geom_line(alpha=0.5) +
  facet_wrap(~location, ncol=1) +
  ylim(0, NA)
```

Kind of works but systematically underestimates some areas. Comparison required against univariate TS is needed. Also needs to incorporate uncertainty.

## Cross-correlation importance

Make separate RFs for each location, and observe the variable importance of cross-correlations.

```{r}
Sensor_Names = unique(X$Sensor_Name)
x = list()
rfs = list()
for (s_n in Sensor_Names) {
  x[[s_n]] = X.train %>% filter(Sensor_Name==s_n)
  rfs[[s_n]] = ranger(Hourly_Counts ~ . -Sensor_Name -Date_Time,
                      data=x[[s_n]], importance="permutation")
}
```

```{r}
for (s_n in Sensor_Names) {
  g = ggplot(data.frame(importance=importance(rfs[[s_n]])) %>%
           rownames_to_column("variable"),
         aes(x=variable, y=importance, fill=importance)) + 
        geom_bar(stat="identity")+ coord_flip()+
        ylab("Variable Importance")+
        xlab("")+
        ggtitle(paste("Importance for", s_n))+
        guides(fill=F)+
        scale_fill_gradient(low="red", high="blue")
  print(g)
}
```

Permutation feature importance: Determines the marginal impact on performance compared to when one feature is randomised (permuted).

```{r, eval=F}
importance_pvalues(rfs[[1]], "altmann", formula=formula("Hourly_Counts ~ . - Sensor_Name - Date_Time"), data=x[[s_n]], num.permutations=10)
```

# Try again on differenced series

```{r, eval=F}
data.ts = raw.ts %>%
  dplyr::select(Date_Time, Sensor_Name, Hourly_Counts) %>%
  spread(key=Sensor_Name, value=Hourly_Counts) %>%
  as.xts(frequency=168) %>%
  as.zoo %>%
  na.contiguous %>%# analysis does not include missing data
  as.data.frame %>%
  mutate(time=as.POSIXct(rownames(.)),
         day=factor(weekdays(time)),
         hour=hour(time))
old.names = names(data.ts)
names(data.ts) = make.names(old.names)
new.names = names(data.ts)

data.ts = data.ts %>%
  dplyr::select(-time, -day, -hour) %>%
  as.xts %>%
  diff(lag=168) %>%
  as.data.frame

lags = list()
lags_ix = c(1:nlag, 24, 168)
for (i in seq_along(lags_ix)) {
  lags[[i]] = data.ts %>%
    dplyr::select(-time, -day, -hour) %>%
    mutate_all(function (x) lead(x, lags_ix[i])) %>%
    rename_all(function(x) paste0(x,".lag", lags_ix[i]))
}
lags = do.call(cbind, lags)

# append the lags onto each current measurement
X = list()
for (j in seq_along(locs)) {
  X[[j]] = cbind(Hourly_Counts=data.ts[,locs[j]], 
                 day=data.ts$day, 
                 hour=data.ts$hour, 
                 time=data.ts$time,
                 location=locs[j],
                 lags)
}
X = do.call(rbind, X) %>%
  drop_na() %>%
  arrange(time)
names(X) = make.names(names(X))
X %>% head %>% kable

X.train = head(X, round(nrow(X)*frac))
X.test = tail(X, round(nrow(X)*(1-frac)))
y.test = X.test %>% pull(Hourly_Counts)
```

```{r}
pred <- predict(rf, X.test)
X.test$pred = pred$predictions
ggplot(X.test, aes(x=Hourly_Counts, y=pred)) +
  geom_point(alpha=0.25)
cat("RMSE", sqrt(mean((X.test$Hourly_Counts-X.test$pred)^2)), "\n")
cat("MAE", mean(abs(X.test$Hourly_Counts-X.test$pred)))

plt.df.train = X.train %>%
  dplyr::select(time, location, train=Hourly_Counts) %>%
  gather(key="key", value="value", -time, -location)
plt.df.test = X.test %>%
  dplyr::select(time, location, obs=Hourly_Counts, fcst=pred) %>%
  gather(key="key", value="value", -time, -location)
plt.df = rbind(plt.df.train, plt.df.test)

ggplot(plt.df %>% filter(location %in% levels(plt.df$location)[1:6]),
       aes(x=time, y=value, color=key)) +
  geom_line(alpha=0.5) +
  facet_wrap(~location, ncol=1) +
  ylim(0, NA)
```